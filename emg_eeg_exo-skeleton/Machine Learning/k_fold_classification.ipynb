{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68f56bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D ,Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D,LSTM\n",
    "from sklearn.metrics import plot_confusion_matrix,roc_curve, roc_auc_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report \n",
    "import re\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92a1091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #images = np.load('/content/drive/MyDrive/images.npy')\n",
    "# def extract_number(string):\n",
    "#     r = re.compile(r'(\\d+)')\n",
    "#     return int(r.findall(string)[0])\n",
    "\n",
    "\n",
    "# dim = (300, 300)\n",
    "# mypath= r'C:\\Users\\phmeay\\Desktop\\Work files\\DTF-PDC\\OPDC\\OPDC\\image files'\n",
    "# onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "# sortedFiles = sorted(onlyfiles ,key=lambda x: extract_number(x) )\n",
    "# images = np.empty((len(sortedFiles),300,300))\n",
    "# for n in range(0, len(sortedFiles)):\n",
    "#   img = cv2.imread( join(mypath,sortedFiles[n]),cv2.IMREAD_GRAYSCALE  )\n",
    "#   images[n] = cv2.resize(img, dim)\n",
    "# label_motion = np.ones((len(images[:,1,1]))-952)\n",
    "# label_therapy = np.zeros((len(images[:,1,1]))-663)\n",
    "# y = np.hstack((label_motion,label_therapy))\n",
    "\n",
    "# print(images.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa6b69cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1615, 656, 875)\n",
      "(1615,)\n"
     ]
    }
   ],
   "source": [
    "#images = np.load('/content/drive/MyDrive/images.npy')\n",
    "def extract_number(string):\n",
    "    r = re.compile(r'(\\d+)')\n",
    "    return int(r.findall(string)[0])\n",
    "\n",
    "\n",
    "dim = (300, 300)\n",
    "mypath= r'C:\\Users\\phmeay\\Desktop\\Work files\\DTF-PDC\\OPDC\\OPDC\\images file'\n",
    "onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "sortedFiles = sorted(onlyfiles ,key=lambda x: extract_number(x) )\n",
    "# images = numpy.empty(len(sortedFiles), dtype=object)\n",
    "images =[]\n",
    "for n in range(0, len(sortedFiles)):\n",
    "  img  = cv2.imread( join(mypath,sortedFiles[n]),cv2.IMREAD_GRAYSCALE  )\n",
    "  images.append(img)\n",
    "  # images[n] = cv2.resize(img, dim)\n",
    "images =np.array(images)\n",
    "label_motion = np.ones((len(images[:,1,1]))-952)\n",
    "label_therapy = np.zeros((len(images[:,1,1]))-663)\n",
    "y = np.hstack((label_motion,label_therapy))\n",
    "\n",
    "print(images.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc119a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= images.reshape((images.shape[0], 656*875))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09f52e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 574000)\n",
      "(404, 574000)\n",
      "(1211,)\n",
      "(404,)\n"
     ]
    }
   ],
   "source": [
    "num_classes =2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f2136d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.30, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "# print(X_train.shape)\n",
    "# print(X_val.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2dff526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "train_norm = X_train.astype('float32')\n",
    "test_norm = X_test.astype('float32')\n",
    "# normalize to range 0-1\n",
    "X_train = train_norm / 255.0\n",
    "X_test = test_norm / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d1037fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e1cf61b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.9)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "670e8336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff8dc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 41)\n",
      "(404, 41)\n",
      "(388, 41)\n"
     ]
    }
   ],
   "source": [
    "train_img_pca = pca.transform(X_train)\n",
    "test_img_pca = pca.transform(X_test)\n",
    "# val_img_pca = pca.transform(X_val)\n",
    "print(train_img_pca.shape)\n",
    "print(test_img_pca.shape)\n",
    "# print(val_img_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b739a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c9f5816",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Score for fold 1: loss of 0.15966983139514923; accuracy of 92.18106865882874%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Score for fold 2: loss of 0.110819973051548; accuracy of 95.04132270812988%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Score for fold 3: loss of 0.3095683753490448; accuracy of 93.388432264328%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Score for fold 4: loss of 0.10456747561693192; accuracy of 96.28099203109741%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Score for fold 5: loss of 0.20280872285366058; accuracy of 94.2148745059967%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss_val: 0.15966983139514923 - Accuracy_val: 92.18106865882874%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss_val: 0.110819973051548 - Accuracy_val: 95.04132270812988%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss_val: 0.3095683753490448 - Accuracy_val: 93.388432264328%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss_val: 0.10456747561693192 - Accuracy_val: 96.28099203109741%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss_val: 0.20280872285366058 - Accuracy_val: 94.2148745059967%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 94.22133803367615 (+- 1.3979286373185242)\n",
      "> Loss: 0.1774868756532669\n",
      "------------------------------------------------------------------------\n",
      "[0.22550652921199799, 0.9331682920455933]\n"
     ]
    }
   ],
   "source": [
    "############### using K-Fold #########################\n",
    "\n",
    "\n",
    "# inputs = np.concatenate((train_img_pca, val_img_pca), axis=0)\n",
    "# targets = np.concatenate((y_train, y_val), axis=0)\n",
    "inputs =train_img_pca\n",
    "targets = y_train\n",
    "\n",
    "# Model configuration\n",
    "\n",
    "batch_size = 50\n",
    "no_epochs = 50\n",
    "\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "# Define the K-fold Cross Validator\n",
    "kfold_traning = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold_traning.split(inputs, targets):\n",
    "    \n",
    "  # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, activation='relu', input_shape=(41,)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "  # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "  \n",
    "    # Fit data to model\n",
    "    history = model.fit(inputs[train], targets[train],\n",
    "                batch_size=batch_size,\n",
    "                epochs=no_epochs,\n",
    "                verbose=0)\n",
    "  \n",
    "    # Generate generalization metrics\n",
    "    \n",
    "    scores_test = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores_test[0]}; {model.metrics_names[1]} of {scores_test[1]*100}%')\n",
    "    acc_per_fold.append(scores_test[1] * 100)\n",
    "    loss_per_fold.append(scores_test[0])\n",
    "    \n",
    "  \n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "final_score = model.evaluate(test_img_pca, y_test, verbose=0)\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss_val: {loss_per_fold[i]} - Accuracy_val: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "print(final_score)\n",
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69adb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7f0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13577fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fab5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
